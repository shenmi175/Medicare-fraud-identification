{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ddb8e0-04b7-4e05-b165-9565ad5889fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline,make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3805c28-3286-476e-a8e3-3bd4f7ed72c3",
   "metadata": {},
   "source": [
    "1. **Borderline-SMOTE**：重点关注靠近多数类边界的少数类样本。这种方法试图仅在这些区域生成合成样本，因为边界区域的样本更容易被误分类。\n",
    "2. **ADASYN (Adaptive Synthetic Sampling)**：与SMOTE类似，但更加关注生成难以学习的少数类样本。ADASYN根据少数类样本邻域中多数类样本的数量，动态调整生成合成样本的数量。\n",
    "4. **SVMSMOTE**：使用支持向量机（SVM）来识别少数类样本和多数类样本之间的边界，并在这个边界附近生成新的样本。\n",
    "5. **K-Means SMOTE**：结合K-Means聚类和SMOTE，通过首先对少数类样本进行聚类，然后在每个聚类内部进行过采样。\n",
    "6. **SMOTE-ENN (SMOTE with Edited Nearest Neighbors)**：这是一种组合方法，首先使用SMOTE进行过采样，然后使用编辑的最近邻（ENN）规则来清除那些可能是噪声的合成样本。\n",
    "7. **SMOTE-Tomek**：结合了SMOTE和Tomek链去除。Tomek链用于清除重叠区域的样本，以提高分类器的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b59d47-48e0-45d8-ac7b-a22490dbd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"E:\\竞赛\\服创赛-A08\\data\\process_data.csv\")\n",
    "# data = pd.read_csv(\"E:\\竞赛\\服创赛-A08\\data\\特征集\\\\new_features.csv\")\n",
    "\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(['Unnamed: 0','个人编码'], axis=1)\n",
    "else:\n",
    "    data = data.drop('个人编码', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcfcf925-503b-411c-87f9-c4e481eccf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当RES列的值为1时，有缺失值的列及其缺失数量：\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 筛选RES列值为1的数据\n",
    "data_res_1 = data[data['RES'] == 1]\n",
    "\n",
    "# 计算RES为1的数据中每列的缺失值数量\n",
    "missing_values_count_res_1 = data_res_1.isnull().sum()\n",
    "\n",
    "# 过滤出有缺失值的列\n",
    "missing_values_res_1 = missing_values_count_res_1[missing_values_count_res_1 > 0]\n",
    "\n",
    "# 打印有缺失值的列和对应的缺失值数量（当RES列的值为1）\n",
    "print(\"当RES列的值为1时，有缺失值的列及其缺失数量：\")\n",
    "print(missing_values_res_1)\n",
    "\n",
    "# 构建的特征集中含有缺失值，部分分类器对缺失值敏感，删除样本\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae34b6a-9c0f-4dd6-b3cf-951f5ee7357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('RES', axis=1)\n",
    "y = data['RES']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec3ffb-f3c0-4e76-89cd-4bb01951c216",
   "metadata": {},
   "source": [
    "# Borderline-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bad6789-db9f-4990-b3e0-52b81afb1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = BorderlineSMOTE(\n",
    "        sampling_strategy=0.5,    # 平衡类分布\n",
    "        k_neighbors=5,            # 使用5个最近邻\n",
    "        m_neighbors=10,           # 边界样本的邻居数量\n",
    "        kind='borderline-1',      # 边界类型选择（'borderline-1' 或 'borderline-2'）\n",
    "        random_state=42           \n",
    ")\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a0705e0-db0f-4acc-8d75-a3e1f3a4b16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5702"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a81e7-bc1f-41a9-8eb7-28de80eea1a9",
   "metadata": {},
   "source": [
    "# ADASYN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc3d5f4-5a2f-4137-b3a9-4124c53abb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = ADASYN(\n",
    "    sampling_strategy=0.5, \n",
    "    n_neighbors=5,            # 使用5个最近邻\n",
    "    random_state=42           \n",
    ")\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d633f07e-b41f-4d0a-8953-a6c37c79141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008514e-2af7-405b-8665-df88bb5432b0",
   "metadata": {},
   "source": [
    "# SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182166a9-d80d-41a9-ad6a-a339a5a9ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SVMSMOTE(\n",
    "    sampling_strategy=0.5, \n",
    "    k_neighbors=5,            # 使用5个最近邻\n",
    "    m_neighbors=10,           # 边界样本的邻居数量\n",
    "    svm_estimator=None,       # 使用默认SVM分类器\n",
    "    random_state=42           \n",
    ")\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57323ed-adfd-4735-bf3a-8fa34602b795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5702"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f75ca-ab69-4925-b828-c3c59d8dce52",
   "metadata": {},
   "source": [
    "# K-Means SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e02bbbc-647f-450f-8fa8-5f9260a1ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\A08\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1972: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 3584 or by setting the environment variable OMP_NUM_THREADS=4\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smote = KMeansSMOTE(\n",
    "    sampling_strategy=0.5,\n",
    "    k_neighbors=10,           # 使用10个最近邻\n",
    "    # n_clusters=2,             # 使用2个簇中心\n",
    "    random_state=42          \n",
    ")\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a206c500-4d22-451f-ab3f-2bc949204e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5702"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba3a72-724a-4568-b32e-d7ed427f2281",
   "metadata": {},
   "source": [
    "# SMOTE-ENN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37baad96-a053-4c9c-ab4a-4e5e4744477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTEENN(\n",
    "    sampling_strategy=0.5,\n",
    "    # smote=SMOTE(),  # 默认使用标准smote计算\n",
    "    enn=None,                 # 使用默认的Edited Nearest Neighbours\n",
    "    random_state=42        \n",
    ")\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98604b1e-fc8d-48b6-a219-1cfc82c6ec9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5484"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "750f7454-597c-4aae-9ab8-c6c14e47443a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9829"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37098462-8945-42ca-9363-571c3920eb18",
   "metadata": {},
   "source": [
    "# SMOTE-Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f90bc41-41ab-42e0-887c-e7ada967eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTETomek(\n",
    "    sampling_strategy=0.5,\n",
    "    smote=None,               # 使用默认SMOTE\n",
    "    tomek=None,               # 使用默认Tomek链\n",
    "    random_state=42          \n",
    ")\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ee7daf-0912-4cdb-926f-a3a1702871c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5683"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03602f6-b79d-45b2-861f-dd89c52cff51",
   "metadata": {},
   "source": [
    "# 使用分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e99b5e-54b1-4932-a84c-70df8ab95c1a",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0e00dc-be3e-4a58-8804-2a283e8b1560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3802\n",
      "           1       0.30      0.49      0.37       198\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.64      0.72      0.66      4000\n",
      "weighted avg       0.94      0.92      0.93      4000\n",
      "\n",
      "Decision Tree AUC Score: 0.7152282955807416\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42,\n",
    "                                 #  max_depth=7,\n",
    "                                 #  min_samples_leaf=10,\n",
    "                                 #  min_samples_split=10,\n",
    "                                 #  class_weight=weight_dict,\n",
    "                                 )\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_probabilities = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_predictions))\n",
    "print(\"Decision Tree AUC Score:\", roc_auc_score(y_test, dt_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6facc5-d879-4b7a-bb63-a5f139fcecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11386\n",
      "           1       1.00      1.00      1.00      5683\n",
      "\n",
      "    accuracy                           1.00     17069\n",
      "   macro avg       1.00      1.00      1.00     17069\n",
      "weighted avg       1.00      1.00      1.00     17069\n",
      "\n",
      "Decision Tree AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "dt_predictions = dt_model.predict(X_train)\n",
    "dt_probabilities = dt_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_train, dt_predictions))\n",
    "print(\"Decision Tree AUC Score:\", roc_auc_score(y_train, dt_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4271723-e6b6-45ed-b850-597000aae61c",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20db6bc0-a6a6-4a2e-9e2d-67bfbf6db977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      3802\n",
      "           1       0.30      0.55      0.39       198\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.64      0.74      0.67      4000\n",
      "weighted avg       0.94      0.92      0.93      4000\n",
      "\n",
      "Logistic Regression AUC Score: 0.8058677251207499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\A08\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_model = make_pipeline(StandardScaler(), LogisticRegression(random_state=42,))\n",
    "log_model.fit(\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "log_predictions = log_model.predict(X_test)\n",
    "log_probabilities = log_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, log_predictions))\n",
    "print(\"Logistic Regression AUC Score:\", roc_auc_score(y_test, log_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac347e8-3b8e-4688-a56c-1445742c1edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     11386\n",
      "           1       0.85      0.63      0.73      5683\n",
      "\n",
      "    accuracy                           0.84     17069\n",
      "   macro avg       0.85      0.79      0.81     17069\n",
      "weighted avg       0.84      0.84      0.83     17069\n",
      "\n",
      "Logistic Regression AUC Score: 0.9093564867332469\n"
     ]
    }
   ],
   "source": [
    "log_predictions = log_model.predict(X_train)\n",
    "log_probabilities = log_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_train, log_predictions))\n",
    "print(\"Logistic Regression AUC Score:\", roc_auc_score(y_train, log_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf345d-7bb4-41da-99da-41643f53cc07",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d634569-9cfa-4b2e-b0a5-74984079189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3802\n",
      "           1       0.55      0.45      0.50       198\n",
      "\n",
      "    accuracy                           0.95      4000\n",
      "   macro avg       0.76      0.72      0.74      4000\n",
      "weighted avg       0.95      0.95      0.95      4000\n",
      "\n",
      "Random Forest AUC Score: 0.919087641273333\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42,\n",
    "                                  # class_weight=weight_dict,\n",
    "                                  # bootstrap=True, \n",
    "                                  # max_samples=100\n",
    "                                 )\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_probabilities = rf_model.predict_proba(X_test)[:, 1]\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "print(\"Random Forest AUC Score:\", roc_auc_score(y_test, rf_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5995ad43-3409-48cf-bd37-4e9fe11de32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11386\n",
      "           1       1.00      1.00      1.00      5683\n",
      "\n",
      "    accuracy                           1.00     17069\n",
      "   macro avg       1.00      1.00      1.00     17069\n",
      "weighted avg       1.00      1.00      1.00     17069\n",
      "\n",
      "Random Forest AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rf_model.predict(X_train)\n",
    "rf_probabilities = rf_model.predict_proba(X_train)[:, 1]\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_train, rf_predictions))\n",
    "print(\"Random Forest AUC Score:\", roc_auc_score(y_train, rf_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a259c-91be-442b-9e70-38f53be516b8",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a5bf59-b33c-4ff2-8676-61518df0fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3802\n",
      "           1       0.43      0.51      0.46       198\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.70      0.73      0.72      4000\n",
      "weighted avg       0.95      0.94      0.94      4000\n",
      "\n",
      "GBDT AUC Score: 0.8903706980377153\n"
     ]
    }
   ],
   "source": [
    "gbdt_model = GradientBoostingClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "gbdt_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "              )\n",
    "\n",
    "\n",
    "gbdt_predictions = gbdt_model.predict(X_test)\n",
    "gbdt_probabilities = gbdt_model.predict_proba(X_test)[:, 1]\n",
    "print(\"GBDT Classification Report:\")\n",
    "print(classification_report(y_test, gbdt_predictions))\n",
    "print(\"GBDT AUC Score:\", roc_auc_score(y_test, gbdt_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df139f93-6f8f-46f8-a509-7c0259698951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     11386\n",
      "           1       0.93      0.90      0.91      5683\n",
      "\n",
      "    accuracy                           0.94     17069\n",
      "   macro avg       0.94      0.93      0.94     17069\n",
      "weighted avg       0.94      0.94      0.94     17069\n",
      "\n",
      "GBDT AUC Score: 0.9861468076891893\n"
     ]
    }
   ],
   "source": [
    "gbdt_predictions = gbdt_model.predict(X_train)\n",
    "gbdt_probabilities = gbdt_model.predict_proba(X_train)[:, 1]\n",
    "print(\"GBDT Classification Report:\")\n",
    "print(classification_report(y_train, gbdt_predictions))\n",
    "print(\"GBDT AUC Score:\", roc_auc_score(y_train, gbdt_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3e5de-4561-49e0-8179-9ffa02f5d0d9",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36406c71-8af6-4bc6-b3fc-8b71e4f9f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5683, number of negative: 11386\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14693\n",
      "[LightGBM] [Info] Number of data points in the train set: 17069, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.332943 -> initscore=-0.694905\n",
      "[LightGBM] [Info] Start training from score -0.694905\n",
      "LightGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3802\n",
      "           1       0.51      0.45      0.48       198\n",
      "\n",
      "    accuracy                           0.95      4000\n",
      "   macro avg       0.74      0.72      0.73      4000\n",
      "weighted avg       0.95      0.95      0.95      4000\n",
      "\n",
      "LightGBM AUC Score: 0.9186247004500554\n"
     ]
    }
   ],
   "source": [
    "lgb_model = LGBMClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    ")\n",
    "\n",
    "lgb_predictions = lgb_model.predict(X_test)\n",
    "lgb_probabilities = lgb_model.predict_proba(X_test)[:, 1]\n",
    "print(\"LightGBM Classification Report:\")\n",
    "print(classification_report(y_test, lgb_predictions))\n",
    "print(\"LightGBM AUC Score:\", roc_auc_score(y_test, lgb_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d172358a-08e8-4011-8390-5cd6d2b7c8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     11386\n",
      "           1       0.99      0.98      0.99      5683\n",
      "\n",
      "    accuracy                           0.99     17069\n",
      "   macro avg       0.99      0.99      0.99     17069\n",
      "weighted avg       0.99      0.99      0.99     17069\n",
      "\n",
      "LightGBM AUC Score: 0.9996284307028902\n"
     ]
    }
   ],
   "source": [
    "lgb_predictions = lgb_model.predict(X_train)\n",
    "lgb_probabilities = lgb_model.predict_proba(X_train)[:, 1]\n",
    "print(\"LightGBM Classification Report:\")\n",
    "print(classification_report(y_train, lgb_predictions))\n",
    "print(\"LightGBM AUC Score:\", roc_auc_score(y_train, lgb_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3aa0e5-892f-4843-b09e-8654f5deb39d",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a1b3def-faa7-4f1e-90e9-387ad99aacf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3802\n",
      "           1       0.56      0.44      0.49       198\n",
      "\n",
      "    accuracy                           0.95      4000\n",
      "   macro avg       0.76      0.71      0.74      4000\n",
      "weighted avg       0.95      0.95      0.95      4000\n",
      "\n",
      "XGBoost AUC Score: 0.9097790105154652\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    ")\n",
    "\n",
    "\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_probabilities = xgb_model.predict_proba(X_test)[:, 1]\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "print(\"XGBoost AUC Score:\", roc_auc_score(y_test, xgb_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55b62fff-6a04-4149-9e71-399285caab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11386\n",
      "           1       1.00      1.00      1.00      5683\n",
      "\n",
      "    accuracy                           1.00     17069\n",
      "   macro avg       1.00      1.00      1.00     17069\n",
      "weighted avg       1.00      1.00      1.00     17069\n",
      "\n",
      "XGBoost AUC Score: 0.9999999845456351\n"
     ]
    }
   ],
   "source": [
    "xgb_predictions = xgb_model.predict(X_train)\n",
    "xgb_probabilities = xgb_model.predict_proba(X_train)[:, 1]\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_train, xgb_predictions))\n",
    "print(\"XGBoost AUC Score:\", roc_auc_score(y_train, xgb_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cccc0-d33d-40dc-a67d-68d5db2cd0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96132d82-c6f7-4142-99dc-3369787fe480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A08",
   "language": "python",
   "name": "a08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
