{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f680ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdd74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   就诊次数_SUM     16000 non-null  int64  \n",
      " 1   药品在总金额中的占比   16000 non-null  float64\n",
      " 2   个人支付的药品占比    16000 non-null  float64\n",
      " 3   检查总费用在总金额占比  16000 non-null  float64\n",
      " 4   治疗费用在总金额占比   16000 non-null  float64\n",
      " 5   就诊的月数        16000 non-null  int64  \n",
      " 6   月就诊天数_MAX    16000 non-null  int64  \n",
      " 7   月就诊天数_AVG    16000 non-null  float64\n",
      " 8   月就诊医院数_MAX   16000 non-null  int64  \n",
      " 9   月就诊医院数_AVG   16000 non-null  float64\n",
      " 10  RES          16000 non-null  int64  \n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 1.3 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   就诊次数_SUM  药品在总金额中的占比  个人支付的药品占比  检查总费用在总金额占比  治疗费用在总金额占比  就诊的月数  月就诊天数_MAX  \\\n",
       " 0        34    0.939194   0.004262     0.050817    0.007434      6          7   \n",
       " 1        15    0.955626   0.002982     0.030815    0.013398      6          4   \n",
       " 2        45    0.783610   0.000332     0.000000    0.195087      6          8   \n",
       " 3        23    0.458649   0.000184     0.000000    0.541351      6          6   \n",
       " 4        26    0.983726   0.000316     0.000000    0.016274      6          5   \n",
       " \n",
       "    月就诊天数_AVG  月就诊医院数_MAX  月就诊医院数_AVG  RES  \n",
       " 0   5.666667           3    2.166667    0  \n",
       " 1   2.500000           2    1.333333    0  \n",
       " 2   6.166667           3    2.166667    0  \n",
       " 3   3.666667           2    1.833333    0  \n",
       " 4   4.333333           1    1.000000    0  ,\n",
       " None,\n",
       "            就诊次数_SUM    药品在总金额中的占比     个人支付的药品占比   检查总费用在总金额占比    治疗费用在总金额占比  \\\n",
       " count  16000.000000  16000.000000  16000.000000  16000.000000  16000.000000   \n",
       " mean      36.818438      0.854763      0.005500      0.039006      0.081316   \n",
       " std       23.656539      0.168843      0.013990      0.064466      0.155653   \n",
       " min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 25%       22.000000      0.845445      0.000003      0.001170      0.015839   \n",
       " 50%       32.000000      0.907803      0.000569      0.016690      0.027925   \n",
       " 75%       46.000000      0.946247      0.004818      0.049281      0.051846   \n",
       " max      307.000000      1.000000      0.689375      0.962401      1.000000   \n",
       " \n",
       "               就诊的月数     月就诊天数_MAX     月就诊天数_AVG    月就诊医院数_MAX    月就诊医院数_AVG  \\\n",
       " count  16000.000000  16000.000000  16000.000000  16000.000000  16000.000000   \n",
       " mean       5.817812      7.824438      5.854813      2.099000      1.735954   \n",
       " std        0.702069      4.193234      3.377273      0.947038      0.724497   \n",
       " min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       " 25%        6.000000      5.000000      3.500000      1.000000      1.000000   \n",
       " 50%        6.000000      7.000000      5.166667      2.000000      1.666667   \n",
       " 75%        6.000000     10.000000      7.333333      3.000000      2.000000   \n",
       " max        7.000000     31.000000     30.000000      8.000000      7.000000   \n",
       " \n",
       "                 RES  \n",
       " count  16000.000000  \n",
       " mean       0.049563  \n",
       " std        0.217046  \n",
       " min        0.000000  \n",
       " 25%        0.000000  \n",
       " 50%        0.000000  \n",
       " 75%        0.000000  \n",
       " max        1.000000  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "file_path = 'E:\\竞赛\\服创赛-A08\\data\\欺诈手段特征集.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 展示数据的前几行以及基本信息\n",
    "data.head(), data.info(), data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f836ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离特征和目标变量\n",
    "X = data.drop('RES', axis=1)\n",
    "y = data['RES']\n",
    "\n",
    "# 分离类别\n",
    "data_majority = data[data.RES == 0]\n",
    "data_minority = data[data.RES == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0ef8f",
   "metadata": {},
   "source": [
    "## 随机森林算法中的重要参数\n",
    "\n",
    "- n_estimators：森林中树的数量。增加树的数量通常会提高模型的性能，但也会增加计算成本和时间。默认通常是100。\n",
    "\n",
    "- max_depth：树的最大深度。这个参数可以控制树的复杂度。较深的树可能会捕捉更多数据特性，但也可能导致过拟合。如果设置为None，则节点将扩展到所有叶子都是纯的或直到所有叶子包含少于min_samples_split样本为止。\n",
    "\n",
    "- min_samples_split：分裂内部节点所需的最小样本数。可以用于控制过拟合。较大的值可以防止模型学习数据中的噪声。\n",
    "\n",
    "- min_samples_leaf：在叶节点处需要的最小样本数。这个参数同样有助于控制过拟合，特别是对于不平衡的数据集。\n",
    "\n",
    "- max_features：寻找最佳分割时要考虑的特征数量。这可以影响每棵树的随机性，以及决策树的构建方式。\n",
    "\n",
    "- bootstrap：是否在构建树时使用bootstrap样本。通常为True，意味着采用有放回的抽样方法。\n",
    "\n",
    "- oob_score：是否使用袋外样本来估计准确度。这是一种使用训练期间未被某些树看到的数据来评估模型的方法。\n",
    "\n",
    "- class_weight：类别的权重。对于不平衡的数据集，可以通过调整类别权重来改善模型性能。设置为“balanced”可以根据样本数量自动调整权重。\n",
    "\n",
    "- random_state：控制森林中树的随机性，以及分裂点的选择。设置一个固定的随机状态可以保证结果的可重复性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440dbf3",
   "metadata": {},
   "source": [
    "## 欠采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19292b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "欠采样比例: 1:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86      3042\n",
      "           1       0.14      0.71      0.23       158\n",
      "\n",
      "    accuracy                           0.77      3200\n",
      "   macro avg       0.56      0.74      0.55      3200\n",
      "weighted avg       0.94      0.77      0.83      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86      3042\n",
      "           1       0.14      0.75      0.24       158\n",
      "\n",
      "    accuracy                           0.76      3200\n",
      "   macro avg       0.56      0.76      0.55      3200\n",
      "weighted avg       0.94      0.76      0.83      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      3041\n",
      "           1       0.15      0.72      0.25       159\n",
      "\n",
      "    accuracy                           0.78      3200\n",
      "   macro avg       0.56      0.75      0.56      3200\n",
      "weighted avg       0.94      0.78      0.84      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87      3041\n",
      "           1       0.16      0.77      0.26       159\n",
      "\n",
      "    accuracy                           0.79      3200\n",
      "   macro avg       0.57      0.78      0.57      3200\n",
      "weighted avg       0.94      0.79      0.84      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.85      3041\n",
      "           1       0.13      0.71      0.22       159\n",
      "\n",
      "    accuracy                           0.75      3200\n",
      "   macro avg       0.56      0.73      0.54      3200\n",
      "weighted avg       0.94      0.75      0.82      3200\n",
      "\n",
      "\n",
      "欠采样比例: 2:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3042\n",
      "           1       0.24      0.57      0.33       158\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.61      0.74      0.64      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3042\n",
      "           1       0.24      0.61      0.34       158\n",
      "\n",
      "    accuracy                           0.88      3200\n",
      "   macro avg       0.61      0.75      0.64      3200\n",
      "weighted avg       0.94      0.88      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      3041\n",
      "           1       0.24      0.54      0.33       159\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.61      0.73      0.64      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3041\n",
      "           1       0.26      0.64      0.37       159\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.62      0.77      0.65      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      3041\n",
      "           1       0.23      0.52      0.32       159\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.60      0.71      0.63      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "\n",
      "欠采样比例: 3:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3042\n",
      "           1       0.30      0.49      0.37       158\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.71      0.66      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3042\n",
      "           1       0.30      0.47      0.37       158\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.71      0.66      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3041\n",
      "           1       0.31      0.48      0.37       159\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.71      0.67      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      3041\n",
      "           1       0.34      0.55      0.42       159\n",
      "\n",
      "    accuracy                           0.93      3200\n",
      "   macro avg       0.66      0.75      0.69      3200\n",
      "weighted avg       0.94      0.93      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      3041\n",
      "           1       0.31      0.45      0.37       159\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.70      0.66      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "\n",
      "欠采样比例: 4:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3042\n",
      "           1       0.39      0.43      0.41       158\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.68      0.70      0.69      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3042\n",
      "           1       0.40      0.42      0.41       158\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.68      0.70      0.69      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3041\n",
      "           1       0.38      0.43      0.40       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.67      0.70      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3041\n",
      "           1       0.41      0.52      0.46       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.69      0.74      0.71      3200\n",
      "weighted avg       0.95      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3041\n",
      "           1       0.35      0.42      0.39       159\n",
      "\n",
      "    accuracy                           0.93      3200\n",
      "   macro avg       0.66      0.69      0.67      3200\n",
      "weighted avg       0.94      0.93      0.94      3200\n",
      "\n",
      "\n",
      "欠采样比例: 5:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3042\n",
      "           1       0.47      0.42      0.45       158\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.72      0.70      0.71      3200\n",
      "weighted avg       0.95      0.95      0.95      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3042\n",
      "           1       0.42      0.37      0.39       158\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.69      0.67      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3041\n",
      "           1       0.41      0.38      0.39       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.69      0.67      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3041\n",
      "           1       0.51      0.48      0.50       159\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.74      0.73      0.74      3200\n",
      "weighted avg       0.95      0.95      0.95      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3041\n",
      "           1       0.39      0.37      0.38       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.68      0.67      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义一个函数来执行带有不同欠采样比例的交叉验证\n",
    "def evaluate_downsampling_ratios(X, y, ratios):\n",
    "    results = {}\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "    for ratio in ratios:\n",
    "        print(f\"\\n欠采样比例: {ratio}:1\")\n",
    "        \n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            # 分割数据\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # 分离多数和少数类\n",
    "            X_train_majority = X_train[y_train == 0]\n",
    "            X_train_minority = X_train[y_train == 1]\n",
    "\n",
    "            # 执行欠采样\n",
    "            majority_sample_size = int(len(X_train_minority) * ratio)\n",
    "            X_train_majority_downsampled = resample(X_train_majority, \n",
    "                                                    replace=False,\n",
    "                                                    n_samples=majority_sample_size,\n",
    "                                                    random_state=123)\n",
    "            y_train_majority_downsampled = y_train.loc[X_train_majority_downsampled.index]\n",
    "\n",
    "            # 合并数据\n",
    "            X_train_downsampled = pd.concat([X_train_majority_downsampled, X_train_minority])\n",
    "            y_train_downsampled = pd.concat([y_train_majority_downsampled, y_train[y_train == 1]])\n",
    "\n",
    "            # 创建并训练模型\n",
    "            RF_1 = RandomForestClassifier(n_estimators=100, random_state=123, n_jobs=-1)\n",
    "            RF_1.fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "            # 预测\n",
    "            y_pred = RF_1.predict(X_test)\n",
    "\n",
    "            # 输出分类报告\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 欠采样比例\n",
    "ratios = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 执行评估\n",
    "evaluate_downsampling_ratios(X, y, ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f2f0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "欠采样比例: 1:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86      3042\n",
      "           1       0.14      0.71      0.23       158\n",
      "\n",
      "    accuracy                           0.77      3200\n",
      "   macro avg       0.56      0.74      0.55      3200\n",
      "weighted avg       0.94      0.77      0.83      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86      3042\n",
      "           1       0.14      0.75      0.24       158\n",
      "\n",
      "    accuracy                           0.76      3200\n",
      "   macro avg       0.56      0.76      0.55      3200\n",
      "weighted avg       0.94      0.76      0.83      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      3041\n",
      "           1       0.15      0.72      0.25       159\n",
      "\n",
      "    accuracy                           0.78      3200\n",
      "   macro avg       0.56      0.75      0.56      3200\n",
      "weighted avg       0.94      0.78      0.84      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87      3041\n",
      "           1       0.16      0.77      0.26       159\n",
      "\n",
      "    accuracy                           0.79      3200\n",
      "   macro avg       0.57      0.78      0.57      3200\n",
      "weighted avg       0.94      0.79      0.84      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.85      3041\n",
      "           1       0.13      0.71      0.22       159\n",
      "\n",
      "    accuracy                           0.75      3200\n",
      "   macro avg       0.56      0.73      0.54      3200\n",
      "weighted avg       0.94      0.75      0.82      3200\n",
      "\n",
      "\n",
      "欠采样比例: 2:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3042\n",
      "           1       0.24      0.57      0.33       158\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.61      0.74      0.64      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3042\n",
      "           1       0.24      0.61      0.34       158\n",
      "\n",
      "    accuracy                           0.88      3200\n",
      "   macro avg       0.61      0.75      0.64      3200\n",
      "weighted avg       0.94      0.88      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      3041\n",
      "           1       0.24      0.54      0.33       159\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.61      0.73      0.64      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3041\n",
      "           1       0.26      0.64      0.37       159\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.62      0.77      0.65      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      3041\n",
      "           1       0.23      0.52      0.32       159\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.60      0.71      0.63      3200\n",
      "weighted avg       0.94      0.89      0.91      3200\n",
      "\n",
      "\n",
      "欠采样比例: 3:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3042\n",
      "           1       0.30      0.49      0.37       158\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.71      0.66      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3042\n",
      "           1       0.30      0.47      0.37       158\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.71      0.66      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3041\n",
      "           1       0.31      0.48      0.37       159\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.71      0.67      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      3041\n",
      "           1       0.34      0.55      0.42       159\n",
      "\n",
      "    accuracy                           0.93      3200\n",
      "   macro avg       0.66      0.75      0.69      3200\n",
      "weighted avg       0.94      0.93      0.93      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      3041\n",
      "           1       0.31      0.45      0.37       159\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.64      0.70      0.66      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n",
      "\n",
      "欠采样比例: 4:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3042\n",
      "           1       0.39      0.43      0.41       158\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.68      0.70      0.69      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3042\n",
      "           1       0.40      0.42      0.41       158\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.68      0.70      0.69      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3041\n",
      "           1       0.38      0.43      0.40       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.67      0.70      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3041\n",
      "           1       0.41      0.52      0.46       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.69      0.74      0.71      3200\n",
      "weighted avg       0.95      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3041\n",
      "           1       0.35      0.42      0.39       159\n",
      "\n",
      "    accuracy                           0.93      3200\n",
      "   macro avg       0.66      0.69      0.67      3200\n",
      "weighted avg       0.94      0.93      0.94      3200\n",
      "\n",
      "\n",
      "欠采样比例: 5:1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3042\n",
      "           1       0.47      0.42      0.45       158\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.72      0.70      0.71      3200\n",
      "weighted avg       0.95      0.95      0.95      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3042\n",
      "           1       0.42      0.37      0.39       158\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.69      0.67      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3041\n",
      "           1       0.41      0.38      0.39       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.69      0.67      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3041\n",
      "           1       0.51      0.48      0.50       159\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.74      0.73      0.74      3200\n",
      "weighted avg       0.95      0.95      0.95      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3041\n",
      "           1       0.39      0.37      0.38       159\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.68      0.67      0.68      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 首先执行 evaluate_downsampling_ratios 函数以输出所有比例下的模型结果\n",
    "evaluate_downsampling_ratios(X, y, ratios)\n",
    "\n",
    "# 然后，定义一个额外的函数或代码块，用于单独训练和返回比例为4的模型\n",
    "def get_specific_ratio_model(X, y, specific_ratio):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    final_model = None\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        # 分割数据\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # 分离多数和少数类\n",
    "        X_train_majority = X_train[y_train == 0]\n",
    "        X_train_minority = X_train[y_train == 1]\n",
    "\n",
    "        # 执行欠采样\n",
    "        majority_sample_size = int(len(X_train_minority) * specific_ratio)\n",
    "        X_train_majority_downsampled = resample(X_train_majority, \n",
    "                                                replace=False,\n",
    "                                                n_samples=majority_sample_size,\n",
    "                                                random_state=123)\n",
    "        y_train_majority_downsampled = y_train.loc[X_train_majority_downsampled.index]\n",
    "\n",
    "        # 合并数据\n",
    "        X_train_downsampled = pd.concat([X_train_majority_downsampled, X_train_minority])\n",
    "        y_train_downsampled = pd.concat([y_train_majority_downsampled, y_train[y_train == 1]])\n",
    "\n",
    "        # 创建并训练模型\n",
    "        RF_1 = RandomForestClassifier(n_estimators=100, random_state=123, n_jobs=-1)\n",
    "        RF_1.fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "        # 更新最后一个模型\n",
    "        final_model = RF_1\n",
    "\n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b713c8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=123)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取比例为4:1的模型\n",
    "specific_ratio = 4\n",
    "RF_1 = get_specific_ratio_model(X, y, specific_ratio)\n",
    "\n",
    "# 输出比例为4的模型\n",
    "RF_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db318f",
   "metadata": {},
   "source": [
    "## 代价敏感学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f59189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4572\n",
      "           1       0.83      0.20      0.32       228\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.90      0.60      0.65      4800\n",
      "weighted avg       0.96      0.96      0.95      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# 构建随机森林模型\n",
    "# n_estimators: 决定树的数量\n",
    "# class_weight: 用于处理不平衡的类别\n",
    "# random_state: 确保结果的可重复性\n",
    "RF_2 = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=123)\n",
    "\n",
    "# 训练模型\n",
    "RF_2.fit(X_train, y_train)\n",
    "\n",
    "# 进行预测\n",
    "y_pred = RF_2.predict(X_test)\n",
    "\n",
    "# 生成分类报告\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76df5c3",
   "metadata": {},
   "source": [
    "## SMOTE方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ab48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c39c5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      4572\n",
      "           1       0.34      0.38      0.36       228\n",
      "\n",
      "    accuracy                           0.94      4800\n",
      "   macro avg       0.65      0.67      0.66      4800\n",
      "weighted avg       0.94      0.94      0.94      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# 应用SMOTE\n",
    "# 创建SMOTE实例\n",
    "smote = SMOTE(\n",
    "    sampling_strategy='auto',  # 自动增加少数类样本数量，使其与多数类相等\n",
    "    random_state=42,          # 控制随机性，保持结果一致性\n",
    "    k_neighbors=3,             # 用于生成合成样本的最近邻数量\n",
    "    n_jobs=None                # 使用的CPU核心数，默认为None，即使用1个核心\n",
    ")\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建随机森林模型\n",
    "RF_3 = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "# 训练模型\n",
    "RF_3.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# 进行预测\n",
    "y_pred = RF_3.predict(X_test)\n",
    "\n",
    "# 生成分类报告\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b251c71",
   "metadata": {},
   "source": [
    "## 阈值移动 RF_1 - - 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a395c7d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RF_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m classification_reports \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thresh \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# 以概率形式获取预测结果\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     y_probs \u001b[38;5;241m=\u001b[39m RF_1\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# 获取正类的概率\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# 应用阈值\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     y_pred_thresh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_probs \u001b[38;5;241m>\u001b[39m thresh, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RF_1' is not defined"
     ]
    }
   ],
   "source": [
    "# 阈值列表\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "# 用于存储不同阈值下的分类报告\n",
    "classification_reports = {}\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # 以概率形式获取预测结果\n",
    "    y_probs = RF_1.predict_proba(X_test)[:, 1] # 获取正类的概率\n",
    "    # 应用阈值\n",
    "    y_pred_thresh = np.where(y_probs > thresh, 1, 0)\n",
    "    # 生成并存储分类报告\n",
    "    classification_reports[thresh] = classification_report(y_test, y_pred_thresh)\n",
    "\n",
    "# 输出每个阈值下的分类报告\n",
    "for thresh, report in classification_reports.items():\n",
    "    print(f\"Threshold: {thresh}\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "100b0bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4572\n",
      "           1       0.72      0.86      0.78       228\n",
      "\n",
      "    accuracy                           0.98      4800\n",
      "   macro avg       0.86      0.92      0.89      4800\n",
      "weighted avg       0.98      0.98      0.98      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置阈值为0.6\n",
    "threshold = 0.6\n",
    "\n",
    "# 以概率形式获取预测结果\n",
    "y_probs = RF_1.predict_proba(X_test)[:, 1] # 获取正类的概率\n",
    "\n",
    "# 应用阈值\n",
    "y_pred_thresh = np.where(y_probs > threshold, 1, 0)\n",
    "\n",
    "# 生成分类报告\n",
    "classification_report_06 = classification_report(y_test, y_pred_thresh)\n",
    "\n",
    "print(classification_report_06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7cf57f-bda2-4652-b4bc-a08eb4729960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9640498610919249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "y_pred_proba = RF_1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 计算AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018600f2",
   "metadata": {},
   "source": [
    "## 阈值移动 RF_2 - - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22751f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3046\n",
      "           1       0.41      0.32      0.36       154\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.69      0.65      0.66      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "Threshold: 0.3\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3046\n",
      "           1       0.49      0.24      0.32       154\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.73      0.61      0.65      3200\n",
      "weighted avg       0.94      0.95      0.94      3200\n",
      "\n",
      "Threshold: 0.4\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3046\n",
      "           1       0.69      0.19      0.30       154\n",
      "\n",
      "    accuracy                           0.96      3200\n",
      "   macro avg       0.83      0.59      0.64      3200\n",
      "weighted avg       0.95      0.96      0.94      3200\n",
      "\n",
      "Threshold: 0.5\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3046\n",
      "           1       0.77      0.16      0.26       154\n",
      "\n",
      "    accuracy                           0.96      3200\n",
      "   macro avg       0.87      0.58      0.62      3200\n",
      "weighted avg       0.95      0.96      0.94      3200\n",
      "\n",
      "Threshold: 0.6\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3046\n",
      "           1       0.78      0.09      0.16       154\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.87      0.54      0.57      3200\n",
      "weighted avg       0.95      0.95      0.94      3200\n",
      "\n",
      "Threshold: 0.7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3046\n",
      "           1       0.73      0.05      0.10       154\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.84      0.53      0.54      3200\n",
      "weighted avg       0.94      0.95      0.93      3200\n",
      "\n",
      "Threshold: 0.8\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3046\n",
      "           1       0.75      0.02      0.04       154\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.85      0.51      0.51      3200\n",
      "weighted avg       0.94      0.95      0.93      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 阈值列表\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "# 用于存储不同阈值下的分类报告\n",
    "classification_reports = {}\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # 以概率形式获取预测结果\n",
    "    y_probs = RF_2.predict_proba(X_test)[:, 1] # 获取正类的概率\n",
    "    # 应用阈值\n",
    "    y_pred_thresh = np.where(y_probs > thresh, 1, 0)\n",
    "    # 生成并存储分类报告\n",
    "    classification_reports[thresh] = classification_report(y_test, y_pred_thresh)\n",
    "\n",
    "# 输出每个阈值下的分类报告\n",
    "for thresh, report in classification_reports.items():\n",
    "    print(f\"Threshold: {thresh}\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9569059",
   "metadata": {},
   "source": [
    "## 阈值移动 RF_3 - - 舍弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48584383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87      3046\n",
      "           1       0.12      0.59      0.21       154\n",
      "\n",
      "    accuracy                           0.78      3200\n",
      "   macro avg       0.55      0.69      0.54      3200\n",
      "weighted avg       0.93      0.78      0.84      3200\n",
      "\n",
      "Threshold: 0.3\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      3046\n",
      "           1       0.17      0.51      0.25       154\n",
      "\n",
      "    accuracy                           0.86      3200\n",
      "   macro avg       0.57      0.69      0.59      3200\n",
      "weighted avg       0.93      0.86      0.89      3200\n",
      "\n",
      "Threshold: 0.4\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95      3046\n",
      "           1       0.22      0.43      0.29       154\n",
      "\n",
      "    accuracy                           0.90      3200\n",
      "   macro avg       0.59      0.68      0.62      3200\n",
      "weighted avg       0.93      0.90      0.91      3200\n",
      "\n",
      "Threshold: 0.5\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3046\n",
      "           1       0.30      0.38      0.33       154\n",
      "\n",
      "    accuracy                           0.93      3200\n",
      "   macro avg       0.63      0.67      0.65      3200\n",
      "weighted avg       0.94      0.93      0.93      3200\n",
      "\n",
      "Threshold: 0.6\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3046\n",
      "           1       0.38      0.31      0.34       154\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.67      0.64      0.65      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "Threshold: 0.7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3046\n",
      "           1       0.44      0.21      0.29       154\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.70      0.60      0.63      3200\n",
      "weighted avg       0.94      0.95      0.94      3200\n",
      "\n",
      "Threshold: 0.8\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      3046\n",
      "           1       0.55      0.14      0.23       154\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.75      0.57      0.60      3200\n",
      "weighted avg       0.94      0.95      0.94      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 阈值列表\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "# 用于存储不同阈值下的分类报告\n",
    "classification_reports = {}\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # 以概率形式获取预测结果\n",
    "    y_probs = RF_3.predict_proba(X_test)[:, 1] # 获取正类的概率\n",
    "    # 应用阈值\n",
    "    y_pred_thresh = np.where(y_probs > thresh, 1, 0)\n",
    "    # 生成并存储分类报告\n",
    "    classification_reports[thresh] = classification_report(y_test, y_pred_thresh)\n",
    "\n",
    "# 输出每个阈值下的分类报告\n",
    "for thresh, report in classification_reports.items():\n",
    "    print(f\"Threshold: {thresh}\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26b616",
   "metadata": {},
   "source": [
    "## RF_1 与 RF_2 融合  -  简单平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21b60360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每个模型的预测概率\n",
    "y_probs_RF_1 = RF_1.predict_proba(X_test)[:, 1]  # RF1 的正类概率\n",
    "y_probs_RF_2 = RF_2.predict_proba(X_test)[:, 1]  # RF2 的正类概率\n",
    "\n",
    "# 应用各自的阈值\n",
    "y_pred_RF_1 = np.where(y_probs_RF_1 > 0.6, 1, 0)  # 使用阈值0.6\n",
    "y_pred_RF_2 = np.where(y_probs_RF_2 > 0.5, 1, 0)  # 使用阈值0.5\n",
    "\n",
    "# 计算平均预测\n",
    "y_pred_average = np.round((y_pred_RF_1 + y_pred_RF_2) / 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a95de8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3046\n",
      "           1       0.80      0.16      0.26       154\n",
      "\n",
      "    accuracy                           0.96      3200\n",
      "   macro avg       0.88      0.58      0.62      3200\n",
      "weighted avg       0.95      0.96      0.94      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成分类报告\n",
    "report = classification_report(y_test, y_pred_average)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a514b7",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a350617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1280/1280 [==============================] - 6s 4ms/step - loss: 0.2321 - accuracy: 0.9707 - val_loss: 0.1406 - val_accuracy: 0.9575\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 4s 3ms/step - loss: 0.0316 - accuracy: 0.9955 - val_loss: 0.1392 - val_accuracy: 0.9566\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.1583 - val_accuracy: 0.9578\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.1522 - val_accuracy: 0.9559\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.1582 - val_accuracy: 0.9566\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.1620 - val_accuracy: 0.9563\n",
      "Epoch 7/50\n",
      "1193/1280 [==========================>...] - ETA: 0s - loss: 0.0190 - accuracy: 0.9945"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 训练神经网络\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(stacked_train_features, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(stacked_val_features, y_val))\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 假设 RF1 和 RF2 是训练好的模型\n",
    "# 假设 X_train, y_train, X_val, y_val 是训练和验证数据\n",
    "X_val = X_test\n",
    "y_val = y_test\n",
    "\n",
    "# 使用基模型进行预测\n",
    "train_probs_RF_1 = RF_1.predict_proba(X_train)[:, 1]\n",
    "train_probs_RF_2 = RF_2.predict_proba(X_train)[:, 1]\n",
    "val_probs_RF_1 = RF_1.predict_proba(X_val)[:, 1]\n",
    "val_probs_RF_2 = RF_2.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 准备堆叠特征\n",
    "stacked_train_features = np.column_stack((train_probs_RF_1, train_probs_RF_2))\n",
    "stacked_val_features = np.column_stack((val_probs_RF_1, val_probs_RF_2))\n",
    "\n",
    "# 创建神经网络\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=2, activation='relu'))  # 输入维度为2，因为有两个基模型的预测\n",
    "model.add(Dense(1, activation='sigmoid'))  # 二分类问题\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练神经网络\n",
    "model.fit(stacked_train_features, y_train, epochs=50, batch_size=10, validation_data=(stacked_val_features, y_val))\n",
    "\n",
    "# 使用训练好的模型进行预测和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行预测（我们获取概率的第二列，即正类的预测概率）\n",
    "val_predictions = model.predict(stacked_val_features)\n",
    "\n",
    "# 将概率转换为类别标签（以0.5为阈值）\n",
    "val_predictions = (val_predictions > 0.5).astype(int)\n",
    "\n",
    "# 计算性能指标\n",
    "accuracy = accuracy_score(y_val, val_predictions)\n",
    "classification_rep = classification_report(y_val, val_predictions)\n",
    "\n",
    "print(\"Accuracy on Validation Set:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed2744f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
