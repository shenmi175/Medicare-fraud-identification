{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0260d0-317b-4ea9-990e-19da3dcd1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 不同分类器训练时长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6d0497-2847-4622-a1a0-0f05fbde24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c173a5a1-5891-4b98-b863-98db103a978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"../../data/process_data.csv\")\n",
    "data = pd.read_csv(\"../../data/new_features_data_2.csv\")\n",
    "\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(['Unnamed: 0','个人编码'], axis=1)\n",
    "else:\n",
    "    data = data.drop('个人编码', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6649983d-b7bd-47cc-b647-c0a487307dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当RES列的值为1时，有缺失值的列及其缺失数量：\n",
      "月就诊天数_AVG_病种费用标准差值            3\n",
      "月就诊医院数_MAX_病种费用标准差值           3\n",
      "月就诊医院数_AVG_病种费用标准差值           3\n",
      "就诊次数_SUM_病种费用标准差值             3\n",
      "月就诊次数_MAX_病种费用标准差值            3\n",
      "月就诊次数_AVG_病种费用标准差值            3\n",
      "月统筹金额_MAX_病种费用标准差值            3\n",
      "月统筹金额_AVG_病种费用标准差值            3\n",
      "月药品金额_MAX_病种费用标准差值            3\n",
      "月药品金额_AVG_病种费用标准差值            3\n",
      "医院_就诊天数_MAX_病种费用标准差值          3\n",
      "医院_就诊天数_AVG_病种费用标准差值          3\n",
      "医院_统筹金_MAX_病种费用标准差值           3\n",
      "医院_统筹金_AVG_病种费用标准差值           3\n",
      "医院_药品_MAX_病种费用标准差值            3\n",
      "医院_药品_AVG_病种费用标准差值            3\n",
      "个人账户金额_SUM_病种费用标准差值           3\n",
      "统筹支付金额_SUM_病种费用标准差值           3\n",
      "ALL_SUM_病种费用标准差值              3\n",
      "可用账户报销金额_SUM_病种费用标准差值         3\n",
      "药品费发生金额_SUM_病种费用标准差值          3\n",
      "药品费自费金额_SUM_病种费用标准差值          3\n",
      "药品费申报金额_SUM_病种费用标准差值          3\n",
      "贵重药品发生金额_SUM_病种费用标准差值         3\n",
      "中成药费发生金额_SUM_病种费用标准差值         3\n",
      "中草药费发生金额_SUM_病种费用标准差值         3\n",
      "检查费发生金额_SUM_病种费用标准差值          3\n",
      "检查费自费金额_SUM_病种费用标准差值          3\n",
      "检查费申报金额_SUM_病种费用标准差值          3\n",
      "贵重检查费金额_SUM_病种费用标准差值          3\n",
      "治疗费发生金额_SUM_病种费用标准差值          3\n",
      "治疗费自费金额_SUM_病种费用标准差值          3\n",
      "治疗费申报金额_SUM_病种费用标准差值          3\n",
      "手术费发生金额_SUM_病种费用标准差值          3\n",
      "手术费自费金额_SUM_病种费用标准差值          3\n",
      "手术费申报金额_SUM_病种费用标准差值          3\n",
      "床位费发生金额_SUM_病种费用标准差值          3\n",
      "床位费申报金额_SUM_病种费用标准差值          3\n",
      "医用材料发生金额_SUM_病种费用标准差值         3\n",
      "高价材料发生金额_SUM_病种费用标准差值         3\n",
      "医用材料费自费金额_SUM_病种费用标准差值        3\n",
      "成分输血申报金额_SUM_病种费用标准差值         3\n",
      "其它发生金额_SUM_病种费用标准差值           3\n",
      "其它申报金额_SUM_病种费用标准差值           3\n",
      "一次性医用材料申报金额_SUM_病种费用标准差值      3\n",
      "起付线标准金额_MAX_病种费用标准差值          3\n",
      "起付标准以上自负比例金额_SUM_病种费用标准差值     3\n",
      "医疗救助个人按比例负担金额_SUM_病种费用标准差值    3\n",
      "最高限额以上金额_SUM_病种费用标准差值         3\n",
      "基本统筹基金支付金额_SUM_病种费用标准差值       3\n",
      "公务员医疗补助基金支付金额_SUM_病种费用标准差值    3\n",
      "城乡救助补助金额_SUM_病种费用标准差值         3\n",
      "基本个人账户支付_SUM_病种费用标准差值         3\n",
      "非账户支付金额_SUM_病种费用标准差值          3\n",
      "本次审批金额_SUM_病种费用标准差值           3\n",
      "补助审批金额_SUM_病种费用标准差值           3\n",
      "医疗救助医院申请_SUM_病种费用标准差值         3\n",
      "残疾军人补助_SUM_病种费用标准差值           3\n",
      "一天去两家医院的天数_病种费用标准差值           3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 筛选RES列值为1的数据\n",
    "data_res_1 = data[data['RES'] == 1]\n",
    "\n",
    "# 计算RES为1的数据中每列的缺失值数量\n",
    "missing_values_count_res_1 = data_res_1.isnull().sum()\n",
    "\n",
    "# 过滤出有缺失值的列\n",
    "missing_values_res_1 = missing_values_count_res_1[missing_values_count_res_1 > 0]\n",
    "\n",
    "# 打印有缺失值的列和对应的缺失值数量（当RES列的值为1）\n",
    "print(\"当RES列的值为1时，有缺失值的列及其缺失数量：\")\n",
    "print(missing_values_res_1)\n",
    "\n",
    "# 构建的特征集中含有缺失值，部分分类器对缺失值敏感，删除样本\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10c00502-2660-4672-9616-73703c7d94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('RES', axis=1)\n",
    "y = data['RES']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaa159-bf84-4b0b-8212-2537d3b3e867",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997e9a08-f287-467b-8610-107e05ac0aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练耗时：18.429328203201294 秒\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3802\n",
      "           1       0.82      0.37      0.51       198\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.89      0.68      0.75      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "Random Forest AUC Score: 0.9145306298120606\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "end_time = time.time()  # 记录训练结束时间\n",
    "training_time = end_time - start_time  # 计算训练所花费的时间\n",
    "\n",
    "print(f\"模型训练耗时：{training_time} 秒\")\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_probabilities = rf_model.predict_proba(X_test)[:, 1]\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "print(\"Random Forest AUC Score:\", roc_auc_score(y_test, rf_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e65192-f6dc-4bd5-8e22-16ab223d8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11405\n",
      "           1       1.00      1.00      1.00       595\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "Random Forest AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rf_model.predict(X_train)\n",
    "rf_probabilities = rf_model.predict_proba(X_train)[:, 1]\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_train, rf_predictions))\n",
    "print(\"Random Forest AUC Score:\", roc_auc_score(y_train, rf_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786038f4-d145-47f1-872d-726dcdbc93cd",
   "metadata": {},
   "source": [
    "# GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0708db18-3c82-4ac3-8736-66f14d2afc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练耗时：51.56669878959656 秒\n",
      "GBDT Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3802\n",
      "           1       0.78      0.40      0.53       198\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.87      0.70      0.76      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "GBDT AUC Score: 0.9127353227169114\n"
     ]
    }
   ],
   "source": [
    "gbdt_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "\n",
    "gbdt_model.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()  # 记录训练结束时间\n",
    "training_time = end_time - start_time  # 计算训练所花费的时间\n",
    "\n",
    "print(f\"模型训练耗时：{training_time} 秒\")\n",
    "\n",
    "gbdt_predictions = gbdt_model.predict(X_test)\n",
    "gbdt_probabilities = gbdt_model.predict_proba(X_test)[:, 1]\n",
    "print(\"GBDT Classification Report:\")\n",
    "print(classification_report(y_test, gbdt_predictions))\n",
    "print(\"GBDT AUC Score:\", roc_auc_score(y_test, gbdt_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d025a8b-4d4f-4c49-bbbc-889bfd61b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     11405\n",
      "           1       0.93      0.46      0.62       595\n",
      "\n",
      "    accuracy                           0.97     12000\n",
      "   macro avg       0.95      0.73      0.80     12000\n",
      "weighted avg       0.97      0.97      0.97     12000\n",
      "\n",
      "GBDT AUC Score: 0.9604886549095745\n"
     ]
    }
   ],
   "source": [
    "gbdt_predictions = gbdt_model.predict(X_train)\n",
    "gbdt_probabilities = gbdt_model.predict_proba(X_train)[:, 1]\n",
    "print(\"GBDT Classification Report:\")\n",
    "print(classification_report(y_train, gbdt_predictions))\n",
    "print(\"GBDT AUC Score:\", roc_auc_score(y_train, gbdt_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9289c-08e9-40d6-974c-a395dc2dda5b",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba2f242-880d-4fab-b59c-561c3fcf42bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练耗时：1.9439046382904053 秒\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3802\n",
      "           1       0.71      0.40      0.51       198\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.84      0.70      0.75      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "XGBoost AUC Score: 0.9354778718271616\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()  # 记录训练结束时间\n",
    "training_time = end_time - start_time  # 计算训练所花费的时间\n",
    "\n",
    "print(f\"模型训练耗时：{training_time} 秒\")\n",
    "\n",
    "\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_probabilities = xgb_model.predict_proba(X_test)[:, 1]\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "print(\"XGBoost AUC Score:\", roc_auc_score(y_test, xgb_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b22989d9-4067-4800-b096-0ce08a7f5973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11405\n",
      "           1       1.00      1.00      1.00       595\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "XGBoost AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "xgb_predictions = xgb_model.predict(X_train)\n",
    "xgb_probabilities = xgb_model.predict_proba(X_train)[:, 1]\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_train, xgb_predictions))\n",
    "print(\"XGBoost AUC Score:\", roc_auc_score(y_train, xgb_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe7f8e-4f3e-4ddf-9803-de1e51e90e26",
   "metadata": {},
   "source": [
    "# lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379cc5f2-1f28-46ca-99a8-10912eaee775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 595, number of negative: 11405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12757\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 71\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049583 -> initscore=-2.953246\n",
      "[LightGBM] [Info] Start training from score -2.953246\n",
      "模型训练耗时：1.504951000213623 秒\n",
      "LightGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3802\n",
      "           1       0.72      0.38      0.50       198\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.85      0.69      0.74      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "LightGBM AUC Score: 0.9329380071094958\n"
     ]
    }
   ],
   "source": [
    "lgb_model = LGBMClassifier(random_state=42)\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()  # 记录训练结束时间\n",
    "training_time = end_time - start_time  # 计算训练所花费的时间\n",
    "\n",
    "print(f\"模型训练耗时：{training_time} 秒\")\n",
    "\n",
    "lgb_predictions = lgb_model.predict(X_test)\n",
    "lgb_probabilities = lgb_model.predict_proba(X_test)[:, 1]\n",
    "print(\"LightGBM Classification Report:\")\n",
    "print(classification_report(y_test, lgb_predictions))\n",
    "print(\"LightGBM AUC Score:\", roc_auc_score(y_test, lgb_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d05632-a06b-4c9c-a1d7-ceca18c5f909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11405\n",
      "           1       1.00      0.97      0.99       595\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      0.99      0.99     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "LightGBM AUC Score: 0.9999988210979263\n"
     ]
    }
   ],
   "source": [
    "lgb_predictions = lgb_model.predict(X_train)\n",
    "lgb_probabilities = lgb_model.predict_proba(X_train)[:, 1]\n",
    "print(\"LightGBM Classification Report:\")\n",
    "print(classification_report(y_train, lgb_predictions))\n",
    "print(\"LightGBM AUC Score:\", roc_auc_score(y_train, lgb_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a621a4-952a-4049-98b3-393a9cbe4193",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ddf4bd-08b0-48d4-ada5-fb6d2aa68865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练耗时：2.8408243656158447 秒\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3802\n",
      "           1       0.38      0.46      0.42       198\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.68      0.71      0.69      4000\n",
      "weighted avg       0.94      0.94      0.94      4000\n",
      "\n",
      "Decision Tree AUC Score: 0.7104660492351181\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()  # 记录训练结束时间\n",
    "training_time = end_time - start_time  # 计算训练所花费的时间\n",
    "\n",
    "print(f\"模型训练耗时：{training_time} 秒\")\n",
    "\n",
    "\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_probabilities = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_predictions))\n",
    "print(\"Decision Tree AUC Score:\", roc_auc_score(y_test, dt_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec703e74-f325-4dee-ac67-6de048581d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11405\n",
      "           1       1.00      1.00      1.00       595\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "Decision Tree AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "dt_predictions = dt_model.predict(X_train)\n",
    "dt_probabilities = dt_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_train, dt_predictions))\n",
    "print(\"Decision Tree AUC Score:\", roc_auc_score(y_train, dt_probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3267f3-e245-4b6f-b055-5b19be6e0db3",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e33bf978-f2fb-4085-ae5f-ebd47e88d702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练耗时：21.723883152008057 秒\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3791\n",
      "           1       0.59      0.38      0.46       209\n",
      "\n",
      "    accuracy                           0.95      4000\n",
      "   macro avg       0.78      0.68      0.72      4000\n",
      "weighted avg       0.95      0.95      0.95      4000\n",
      "\n",
      "Logistic Regression AUC Score: 0.8443095520869752\n"
     ]
    }
   ],
   "source": [
    "log_model = make_pipeline(StandardScaler(), LogisticRegression(random_state=42,max_iter=500))\n",
    "\n",
    "start_time = time.time()  # 记录训练开始时间\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()  # 记录训练结束时间\n",
    "training_time = end_time - start_time  # 计算训练所花费的时间\n",
    "\n",
    "print(f\"模型训练耗时：{training_time} 秒\")\n",
    "\n",
    "log_predictions = log_model.predict(X_test)\n",
    "log_probabilities = log_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, log_predictions))\n",
    "print(\"Logistic Regression AUC Score:\", roc_auc_score(y_test, log_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25b9cca9-861a-4dfc-82dd-013f3de5a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     11416\n",
      "           1       0.93      0.54      0.69       581\n",
      "\n",
      "    accuracy                           0.98     11997\n",
      "   macro avg       0.95      0.77      0.84     11997\n",
      "weighted avg       0.97      0.98      0.97     11997\n",
      "\n",
      "Logistic Regression AUC Score: 0.9608394535193532\n"
     ]
    }
   ],
   "source": [
    "log_predictions = log_model.predict(X_train)\n",
    "log_probabilities = log_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_train, log_predictions))\n",
    "print(\"Logistic Regression AUC Score:\", roc_auc_score(y_train, log_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a79c0-cf2f-49c0-8c5f-f63bb9e796a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A08",
   "language": "python",
   "name": "a08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
